---
title: "Climate-RL simulation"
author: "Gilles Lijnzaad"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: TRUE
    toc_float:
      collapsed: TRUE
    highlight: tango
    number_sections: true
---

```{r setup, include = FALSE}
knitr::knit_hooks$set(purl = knitr::hook_purl)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(fig.width = 10, fig.height = 4)
```

# Preparation
Defining experimental parameters (i.e., number of participants and number of trials) and standard free parameters for the model.
```{r prep}
n_participants <- 20
n_trials <- 40
params_std <- c(0.5, 0.5, 6, 3) # LR, inv_temp, Q_F_1, Q_U_1
set.seed(1234)
```

I define rating as a function in order to easily edit it later on. For now, I say that rating is drawn from a truncated normal distribution (bounds [1, 10]).
```{r fun-rating}
library(truncnorm)
mu_R <- 5
sigma_R <- 3
rating <- function() {
  R <- round(rtruncnorm(n = 1, a = 1, b = 10, 
                        mean = mu_R, 
                        sd = sigma_R), 
             0)
  return(R)
}
```

# Model definition
For each participant, I first initialize parameters and then run a number of trials. This fills up a data frame that gets added to the total data `dat`. 

```{r model-std}
run_model <- function(params = params_std) {
  dat <- data.frame()

  for (j in 1:n_participants) {

    # ------ init data frames etc -----
    Q <- data.frame(
      F = rep(NA, n_trials),
      U = rep(NA, n_trials)
    )
    P_F <- c()
    choice <- c()
    R <- c()
    pred_err <- c()

    # ----- initialize parameters -----
    LR <- params[1]
    inv_temp <- params[2]
    Q$F[1] <- params[3]
    Q$U[1] <- params[4]

    # --------- run trials ------------
    for (t in 1:n_trials) {

      # choose
      P_F[t] <- 1 / (1 + exp(-inv_temp * (Q$F[t] - Q$U[t])))
      choice[t] <- if_else(runif(1) < P_F[t],
                          "F",
                          "U")

      # rate
      R[t] <- rating()

      # learn
      pred_err[t] <- R[t] - Q[t, choice[t]]

      if (t < n_trials) {   # no updating Qs in the very last trial
        Q[t+1, choice[t]] <- Q[t, choice[t]] + LR * pred_err[t]

        not_chosen <- colnames(Q[which(colnames(Q) != choice[t])])
        Q[t+1, not_chosen] <- Q[t, not_chosen]
      }
    }

    dat_p <- data.frame(
      participant = rep(j, n_trials),
      trial =       1:n_trials,
      Q_F =         Q$F,
      Q_U =         Q$U,
      P_F =         P_F,
      choice =      choice,
      R =           R,
      pred_err =    pred_err
    )

    dat <- rbind(dat, dat_p)
  }

  return(dat)
}
```

# Helper functions
## Plots
I want to create plots of Q over time. I define functions for transforming the data to a long format and for plotting, to make plotting quick and easy.

```{r plot-util}
library(tidyverse)
my_teal <- "#008080"
my_pink <- "#ff00dd"

my_theme <- theme_bw() +
  theme(plot.title = element_text(size = 20, face = "bold")) +
  theme(axis.text = element_text(size = 16),
        axis.title = element_text(size = 18)) +
  theme(legend.title = element_text(size = 18, face = "bold"),
        legend.text = element_text(size = 16)) +
  theme(strip.text.x = element_text(size = 18, face = "bold"))
```

```{r helper-fun}
library(grid)
library(gridExtra)

to_long <- function(dat) {
  long_dat <- dat %>%
    pivot_longer(c(Q_F, Q_U), names_prefix = "Q_", names_to = "option", values_to = "Q") %>%
    mutate(option = factor(option),
           choice = factor(choice))

  return(long_dat)
}

plot_Q <- function(dat) {
  p <- ggplot(dat, aes(x = trial,
                      y = Q,
                      color = option)) +
    geom_smooth(aes(fill = option)) +
    ylim(c(1, 10)) +
    labs(x = "Trial") +
    scale_color_manual(values = c(my_teal, my_pink),
                      labels = c("Friendly", "Unfriendly")) +  
    scale_fill_manual(values = c(my_teal, my_pink),
                      labels = c("Friendly", "Unfriendly")) +
    my_theme
  return(p)
}

plot_choice <- function(dat) {
  dat <- dat %>%
    mutate(choice_is_F = if_else(choice == "F", 1, 0),
           choice_is_U = 1 - choice_is_F)
    
  p <- ggplot(dat, aes(x = trial)) +
    geom_smooth(aes(y = choice_is_F),
                color = paste0(my_teal, "30"),
                fill = paste0(my_teal, "30")) +
    geom_smooth(aes(y = choice_is_U),
                color = paste0(my_pink, "30"),
                fill = paste0(my_pink, "30")) +
    ylim(c(0, 1)) +
    labs(x = "Trial",
         y = "Proportion chosen") +
    my_theme
  return(p)
}

annotation_single <- function(params, x = 0.95) {
    text <- paste0("LR = ", params[1],
                  "\ninv_temp = ", params[2],
                  "\ninitQF = ", params[3],
                  "\ninitQU = ", params[4],
                  "\nmu_R = ", mu_R)

    grid.text(text, x = unit(x, "npc"), y = unit(0.95, "npc"), hjust = 1, vjust = 1)
}

annotation_double <- function(params_left, params_right) {
  annotation_single(params_left, 0.45)
  annotation_single(params_right, 0.95)
}
```

## Data to JSON for Stan
I want to plug simulated data into Stan for model recovery. To this end, I need to convert the relevant data points to JSON format.
```{r dat-to-JSON}
library(cmdstanr) # contains function write_stan_json()
write_sim_dat_JSON <- function(params, model_dat) {
  # parameter settings
  LR <- params[1]
  inv_temp <- params[2]
  initQF <- params[3]
  initQU <- params[4]
  T <- n_trials
  n_part <- n_participants
  list_param_settings <- list(LR, inv_temp, initQF, initQU, mu_R, sigma_R, T, n_part)
  names(list_param_settings) <- c("LR", "inv_temp", "initQF", "initQU", "mu_R", "sigma_R", "T", "n_part")
  write_stan_json(list_param_settings, file = "~/research/climate-RL/R_simulation/sim_param_settings.json")

  # data
  # goal: choice[n_part, T]. see code Jessica
  choice <- matrix(as.numeric(model_dat$choice == "U") + 1,
                   nrow = n_part,
                   ncol = T)
  R <- matrix(model_dat$R,
              nrow = n_part,
              ncol = T)
  list_dat <- list(n_part, T ,choice, R)
  names(list_dat) <- c("n_part", "T", "choice", "R")
  write_stan_json(list_dat, file = "~/research/climate-RL/R_simulation/sim_dat.json")
}
```

# Run & inspect
## Standard settings
```{r run-std, warning = FALSE}
file_path <- "~/research/climate-RL/R_simulation/"

dat_std <- run_model()
write_sim_dat_JSON(params_std, dat_std)
dat_std <- dat_std %>% to_long()
p_left <- plot_Q(dat_std)
p_right <- plot_choice(dat_std)
grid.arrange(p_left, p_right, nrow = 1)
annotation_single(params_std)
```

## Differential initial values
```{r run-std-init-val, warning = FALSE}
params <- c(0.5, 0.5, 8, 3)
dat <- run_model(params)
dat <- dat %>% to_long()
p_left <- plot_Q(dat)
p_right <- plot_choice(dat)
grid.arrange(p_left, p_right, nrow = 1)
annotation_single(params)
```
Even with differential initial values, Q-values quickly converge due to the stochastic nature of the rating function.

## Varying learning rate
The code for this and all other plots is the same as the code in 3.1, just different `params`, so it will not be included.
```{r run-std-LR, echo = FALSE, warning = FALSE}
params <- c(0.2, 0.5, 5, 5)
dat <- run_model(params) %>% to_long()
p_left <- plot_Q(dat)
p_right <- plot_choice(dat)
grid.arrange(p_left, p_right, nrow = 1)
annotation_single(params)

params <- c(0.8, 0.5, 5, 5)
dat <- run_model(params) %>% to_long()
p_left <- plot_Q(dat)
p_right <- plot_choice(dat)
grid.arrange(p_left, p_right, nrow = 1)
annotation_single(params)
```
A lower learning rate results in a smaller effect of ratings, and therefore less variance in Q values (ribbons are smaller). A higher learning rate does the opposite.

## Varying inverse temperature
```{r run-std-inv-temp, echo = FALSE}
params <- c(0.5, 0, 5, 5)
dat <- run_model(params) %>% to_long()
p_left <- plot_Q(dat)
p_right <- plot_choice(dat)
grid.arrange(p_left, p_right, nrow = 1)
annotation_single(params)

params <- c(0.5, 1.5, 5, 5)
dat <- run_model(params) %>% to_long()
p_left <- plot_Q(dat)
p_right <- plot_choice(dat)
grid.arrange(p_left, p_right, nrow = 1)
annotation_single(params)
```
The inverse temperature has a direct effect on the choice probabilities only, and therefore has an *indirect* effect on Q values by determining the option that gets its Q-value updated next trial. 

# Modifying the model: confirmation bias

Confirmation bias may occur at the level of learning and/or at the level of rating. For both options, the question is: how do we quantify whether an outcome confirms or disconfirms currently held beliefs? 

For now, I use the difference between the rating of an outcome and the initial value of that option. If the difference between rating and initial value is larger than some threshold (I picked 2 for now), the outcome is seen as a disconfirmatory outcome; otherwise it is a confirmatory outcome. 

```{r fun-conf}
threshold <- 2

is_confirm <- function(rating, init_value) {
  return(abs(rating - init_value) <= threshold)
}
```

## Dual learning rates

Confirmatory and disconfirmatory outcomes have separate learning rates, where LR_conf > LR_disconf. As a standard, we say LR_conf = 0.7 and LR_disconf = 0.3.

```{r model-dualLR}
params_std <- c(0.7, 0.3, 0.5, 8, 4) # LR_conf, LR_disconf, inv_temp, Q_F_1, Q_U_1

run_model_dualLR <- function(params = params_std) {
  dat <- data.frame()

  for (j in 1:n_participants) {

    # ------ init data frames etc -----
    Q <- data.frame(
      F = rep(NA, n_trials),
      U = rep(NA, n_trials)
    )
    P_F <- c()
    choice <- c()
    R <- c()
    pred_err <- c()

    # ----- initialize parameters -----
    LR_conf <- params[1]
    LR_disconf <- params[2]
    inv_temp <- params[3]
    Q$F[1] <- params[4]
    Q$U[1] <- params[5]

    # --------- run trials ------------
    for (t in 1:n_trials) {

      # choose
      P_F[t] <- 1 / (1 + exp(-inv_temp * (Q$F[t] - Q$U[t])))
      choice[t] <- if_else(runif(1) < P_F[t],
                          "F",
                          "U")

      # rate
      R[t] <- rating()

      # learn
      pred_err[t] <- R[t] - Q[t, choice[t]]

      # which learning rate?
      LR <- if_else(is_confirm(R[t], Q[1, choice[t]]),
                    LR_conf,
                    LR_disconf)

      if (t < n_trials) {   # no updating Qs in the very last trial
        Q[t+1, choice[t]] <- Q[t, choice[t]] + LR * pred_err[t]

        not_chosen <- colnames(Q[which(colnames(Q) != choice[t])])
        Q[t+1, not_chosen] <- Q[t, not_chosen]
      }
    }

    dat_p <- data.frame(
      participant = rep(j, n_trials),
      trial =       1:n_trials,
      Q_F =         Q$F,
      Q_U =         Q$U,
      P_F =         P_F,
      choice =      choice,
      R =           R,
      pred_err =    pred_err
    )

    dat <- rbind(dat, dat_p)
  }

  return(dat)
}
```

```{r helper-fun-2, echo = FALSE}
annotation_single <- function(params, x = 0.95) {
  text <- paste0("LR_conf = ", params[1],
               "\nLR_disconf = ", params[2], 
               "\ninv_temp = ", params[3],
               "\nQ_F[1] = ", params[4],
               "\nQ_U[1] = ", params[5])

  grid.text(text, x = unit(x, "npc"), y = unit(0.95, "npc"), hjust = 1, vjust = 1)
}
```

```{r run-dualLR}
dat <- run_model_dualLR() %>% to_long()
p_left <- plot_Q(dat)
p_right <- plot_choice(dat)
grid.arrange(p_left, p_right, nrow = 1)
annotation_single(params_std)
```

## Rating bias
There are multiple ways of implementing bias at the level of rating. I look at two: adding a bonus to (or subtracting a penalty from) the rating, or drawing the rating from two differential normal distributions.

### Bonus/penalty to rating
```{r fun-rating-bonus}
bonus <- 3

rating <- function(init_value_chosen, init_value_not_chosen) {
  R <- round(rtruncnorm(n = 1, a = 1, b = 10, 
                        mean = 5, 
                        sd = 3), 
             0)

  if (init_value_chosen > init_value_not_chosen) {
    bonus_polarity <- 1
  } else if (init_value_chosen < init_value_not_chosen) {
    bonus_polarity <- -1
  } else {
    bonus_polarity <- 0
  }

  R <- R + 
    is_confirm(R, init_value_chosen) * bonus * bonus_polarity
  return(min(R, 10))    # max rating is still 10
}
```
```{r model-rating-bonus, echo = FALSE}
run_model <- function(params = params_std) {
  dat <- data.frame()

  for (j in 1:n_participants) {

    # ------ init data frames etc -----
    Q <- data.frame(
      F = rep(NA, n_trials),
      U = rep(NA, n_trials)
    )
    P_F <- c()
    choice <- c()
    R <- c()
    pred_err <- c()

    # ----- initialize parameters -----
    LR <- params[1]
    inv_temp <- params[2]
    Q$F[1] <- params[3]
    Q$U[1] <- params[4]

    # --------- run trials ------------
    for (t in 1:n_trials) {

      # choose
      P_F[t] <- 1 / (1 + exp(-inv_temp * (Q$F[t] - Q$U[t])))
      choice[t] <- if_else(runif(1) < P_F[t],
                          "F",
                          "U")
      not_chosen <- colnames(Q[which(colnames(Q) != choice[t])])

      # rate
      R[t] <- rating(Q[1, choice[t]],
                     Q[1, not_chosen])

      # learn
      pred_err[t] <- R[t] - Q[t, choice[t]]

      if (t < n_trials) {   # no updating Qs in the very last trial
        Q[t+1, choice[t]] <- Q[t, choice[t]] + LR * pred_err[t]

        Q[t+1, not_chosen] <- Q[t, not_chosen]
      }
    }

    dat_p <- data.frame(
      participant = rep(j, n_trials),
      trial =       1:n_trials,
      Q_F =         Q$F,
      Q_U =         Q$U,
      P_F =         P_F,
      choice =      choice,
      R =           R,
      pred_err =    pred_err
    )

    dat <- rbind(dat, dat_p)
  }

  return(dat)
}

annotation_single <- function(params, x = 0.95) {
    text <- paste0("LR = ", params[1],
                  "\ninv_temp = ", params[2],
                  "\nQ_F[1] = ", params[3],
                  "\nQ_U[1] = ", params[4])

    grid.text(text, x = unit(x, "npc"), y = unit(0.95, "npc"), hjust = 1, vjust = 1)
}
```

```{r run-rating-bonus, warning = FALSE}
params <- c(0.5, 0.5, 6, 4) # LR, inv_temp, Q_F_1, Q_U_1
dat <- run_model(params) %>% to_long()
p_left <- plot_Q(dat)
p_right <- plot_choice(dat)
grid.arrange(p_left, p_right, nrow = 1)
annotation_single(params)
```

A bonus of 3 is 

### Draw rating from separate distributions
```{r fun-rating-diffdistr}
rating <- function(init_value) {
  R <- round(rtruncnorm(n = 1, a = 1, b = 10, 
                        mean = init_value, 
                        sd = 3), 
             0)
  return(R)
}
```
```{r model-rating-diffdistr, echo = FALSE}
run_model <- function(params = params_std) {
  dat <- data.frame()

  for (j in 1:n_participants) {

    # ------ init data frames etc -----
    Q <- data.frame(
      F = rep(NA, n_trials),
      U = rep(NA, n_trials)
    )
    P_F <- c()
    choice <- c()
    R <- c()
    pred_err <- c()

    # ----- initialize parameters -----
    LR <- params[1]
    inv_temp <- params[2]
    Q$F[1] <- params[3]
    Q$U[1] <- params[4]

    # --------- run trials ------------
    for (t in 1:n_trials) {

      # choose
      P_F[t] <- 1 / (1 + exp(-inv_temp * (Q$F[t] - Q$U[t])))
      choice[t] <- if_else(runif(1) < P_F[t],
                          "F",
                          "U")

      # rate
      R[t] <- rating(Q[1, choice[t]])

      # learn
      pred_err[t] <- R[t] - Q[t, choice[t]]

      if (t < n_trials) {   # no updating Qs in the very last trial
        Q[t+1, choice[t]] <- Q[t, choice[t]] + LR * pred_err[t]

        not_chosen <- colnames(Q[which(colnames(Q) != choice[t])])
        Q[t+1, not_chosen] <- Q[t, not_chosen]
      }
    }

    dat_p <- data.frame(
      participant = rep(j, n_trials),
      trial =       1:n_trials,
      Q_F =         Q$F,
      Q_U =         Q$U,
      P_F =         P_F,
      choice =      choice,
      R =           R,
      pred_err =    pred_err
    )

    dat <- rbind(dat, dat_p)
  }

  return(dat)
}

annotation_single <- function(params, x = 0.95) {
    text <- paste0("LR = ", params[1],
                  "\ninv_temp = ", params[2],
                  "\nQ_F[1] = ", params[3],
                  "\nQ_U[1] = ", params[4])

    grid.text(text, x = unit(x, "npc"), y = unit(0.95, "npc"), hjust = 1, vjust = 1)
}
```

```{r run-rating-diffdistr, warning = FALSE}
params <- c(0.5, 0.5, 7, 3) # LR, inv_temp, Q_F_1, Q_U_1
dat <- run_model(params) %>% to_long()
p_left <- plot_Q(dat)
p_right <- plot_choice(dat)
grid.arrange(p_left, p_right, nrow = 1)
annotation_single(params)
```