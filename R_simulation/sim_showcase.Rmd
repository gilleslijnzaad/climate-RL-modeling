---
title: "Simulation showcase"
author: "Gilles Lijnzaad"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: TRUE
    toc_float:
      collapsed: TRUE
    highlight: tango
    code_folding: hide
---

```{r setup, include = FALSE}
knitr::knit_hooks$set(purl = knitr::hook_purl)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(fig.width = 10, fig.height = 4)
```

In this document, I demonstrate the behavior of the simulation by varying the parameter settings and visualizing the resulting behavior. The full simulation code can be found in [sim.R](sim.R), and all plot-related functions come from [plot_utils.R](../plot_utils.R).

# 0. Simulation code
For ease of reference, here is the simulation code.
```{r sim-code, comment = NA}
rm(list = ls())
sim <- new.env()
source("sim.R", local = sim)  # access functions using sim$fun()
temp <- readLines("sim.R")
start <- grep("# === run_sim", temp)
end <- grep("# === end of run_sim", temp) - 1
cat(temp[start:end], sep = "\n")
```

# 1. Standard settings
```{r run-std}
params_std <- list(
  n_part = 50,
  n_trials = 30,
  LR = 0.4,
  inv_temp = 0.5,
  initQF = 5,
  initQU = 5,
  mu_R = c(8, 2), # F and U
  sigma_R = 1
)

dat <- sim$run_sim(params_std)

plot <- new.env()
source("../plot_utils.R", local = plot)  # access functions using plot$fun()

gridExtra::grid.arrange(plot$Q(dat), plot$choice(dat), nrow = 1)
plot$param_annotation(params_std)
```

# 2. Varying learning rate
```{r run-std-LR}
params <- modifyList(params_std, list(LR = 0.2))
dat <- sim$run_sim(params)
gridExtra::grid.arrange(plot$Q(dat), plot$choice(dat), nrow = 1)
plot$param_annotation(params_std)

params <- modifyList(params_std, list(LR = 0.8))
dat <- sim$run_sim(params)
gridExtra::grid.arrange(plot$Q(dat), plot$choice(dat), nrow = 1)
plot$param_annotation(params_std)
```

# 3. Varying inverse temperature
```{r run-std-inv-temp}
params <- modifyList(params_std, list(inv_temp = 0))
dat <- sim$run_sim(params)
gridExtra::grid.arrange(plot$Q(dat), plot$choice(dat), nrow = 1)
plot$param_annotation(params_std)

params <- modifyList(params_std, list(inv_temp = 1.5))
dat <- sim$run_sim(params)
gridExtra::grid.arrange(plot$Q(dat), plot$choice(dat), nrow = 1)
plot$param_annotation(params_std)
```

# 4. Confirmation bias

The [decision tree](../confirmation_bias_overview/confirmation_bias_models_v3.pdf) shows the many options we have for implementing confirmation bias.

The first differentiation is whether bias occurs at the level of learning (LRN) or the level of rating (RTN).

## Learning: LRN
We assume that the relationship between confirmation and learning rate (LR) is either discrete (discr) or continuous (cont).

### Discrete (discr)
Confirmatory and disconfirmatory outcomes have separate learning rates, where LR_conf > LR_disconf. As a standard, we say LR_conf = 0.7 and LR_disconf = 0.3.

### Continuous (cont)

## Rating: RTN